{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eamirhn/Kaggle-Projects/blob/main/ChatBot_Medical.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f27n8ymUHPg3",
        "outputId": "e3091ef3-4650-4b3c-8dfa-54405ce2949d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip -q install gpt4all"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZDF2DeAHIme",
        "outputId": "40fcb071-c697-47f9-be1b-c08927788576"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: 100%|██████████| 4.66G/4.66G [02:38<00:00, 29.5MiB/s]\n",
            "Verifying: 100%|██████████| 4.66G/4.66G [00:14<00:00, 315MiB/s]\n"
          ]
        }
      ],
      "source": [
        "from gpt4all import GPT4All\n",
        "model = GPT4All(\"Meta-Llama-3-8B-Instruct.Q4_0.gguf\") # downloads / loads a 4.66GB LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwDQmeYqHWAS",
        "outputId": "4432828c-c4ae-4667-9bbb-143b31284da0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A fascinating topic!\n",
            "\n",
            "Yes, I'm familiar with brain tumors and radiomic features.\n",
            "\n",
            "Let's break down the three radiomic features you provided:\n",
            "\n",
            "1. **Original_Shape_Elongation**: This feature measures the elongation of a tumor shape in its original (native) space. Elongation is defined as the ratio of the longest axis to the shortest axis of an object, which can be thought of as a measure of how \"stretched out\" or irregularly shaped the tumor is. A value close to 1 indicates that the tumor has a more spherical shape, while values closer to 0 indicate a more elongated or linear shape.\n",
            "\n",
            "Value: 0.7532 ( moderate elongation)\n",
            "\n",
            "2. **Original_Firstorder_Energy**: This feature represents the first-order statistical moment of an image's intensity histogram, which is related to the distribution of pixel intensities within the tumor region. In this case, the value is extremely high (~1.25 million), indicating a very broad and dispersed intensity distribution in the original space.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "text = \"\"\"\n",
        "Analyze the following radiomic features of a brain tumor and provide a brief explanation:\n",
        "    'original_shape_Elongation': 0.7532,\n",
        "    'original_firstorder_Energy': 1256789.3245,\n",
        "    'original_glcm_Correlation': 0.9876,\n",
        "\"\"\"\n",
        "with model.chat_session():\n",
        "    print(model.generate(f\"Are you Famillier with brian tumors? {text}\", max_tokens=210))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgEhZuKs3ZOX"
      },
      "source": [
        "# Simple Method RAG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N15v1emazdDW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from gpt4all import GPT4All\n",
        "\n",
        "# Define the RetrievalSystem class\n",
        "class RetrievalSystem:\n",
        "    def __init__(self, file_paths):\n",
        "        self.data = self.load_files(file_paths)\n",
        "\n",
        "    def load_files(self, file_paths):\n",
        "        data = []\n",
        "        for file_path in file_paths:\n",
        "            try:\n",
        "                with open(file_path, 'r') as file:\n",
        "                    data.append(file.read())\n",
        "            except FileNotFoundError:\n",
        "                print(f\"Error: File not found - {file_path}\")\n",
        "        return data\n",
        "\n",
        "    def retrieve(self, query):\n",
        "        # Simple retrieval: return all content for demo purposes\n",
        "        # In a real-world scenario, you would implement a more sophisticated retrieval method\n",
        "        return ' '.join(self.data)\n",
        "\n",
        "# Initialize the retrieval system with the paths to the .txt files\n",
        "file_paths = ['file1.txt', 'file2.txt', 'file3.txt']\n",
        "retrieval_system = RetrievalSystem(file_paths)\n",
        "\n",
        "# Initialize the GPT-4 model\n",
        "model = GPT4All(\"Meta-Llama-3-8B-Instruct.Q4_0.gguf\")\n",
        "\n",
        "# Function to generate diagnosis using RAG\n",
        "def generate_diagnosis(query):\n",
        "    # Retrieve relevant information\n",
        "    retrieved_data = retrieval_system.retrieve(query)\n",
        "\n",
        "    # Combine retrieved data with the query for context\n",
        "    augmented_query = f\"{query}\\n{retrieved_data}\"\n",
        "\n",
        "    # Generate response using the model\n",
        "    with model.chat_session():\n",
        "        response = model.generate(augmented_query, max_tokens=210)\n",
        "\n",
        "    return response\n",
        "\n",
        "# Example usage\n",
        "output = generate_diagnosis(\"What are the symptoms of brain tumors?\")\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cCke4Te3eTR"
      },
      "source": [
        "# Better Version RAG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IaLLfxmUKijm",
        "outputId": "571edab8-b2b5-499b-c5e9-4f86efa2b58e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully read Correlation.txt\n",
            "Successfully read Energy.txt\n",
            "Successfully read Elongation.txt\n",
            "\n",
            "Total documents read: 3\n",
            "\n",
            "Document 1 preview:\n",
            "The Gray-Level Co-Occurrence Matrix (GLCM) correla...\n",
            "\n",
            "Document 2 preview:\n",
            "First-order energy is a texture feature derived fr...\n",
            "\n",
            "Document 3 preview:\n",
            "Elongation is a shape feature that describes the r...\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# List to store the content of the files\n",
        "documents = []\n",
        "\n",
        "# List of file names\n",
        "file_names = ['Correlation.txt', 'Energy.txt', 'Elongation.txt']\n",
        "\n",
        "# Directory where the files are located\n",
        "# If the files are in the same directory as the script, you can leave this as an empty string\n",
        "directory = '/content/'\n",
        "\n",
        "# Loop through each file\n",
        "for file_name in file_names:\n",
        "    # Construct the full file path\n",
        "    file_path = os.path.join(directory, file_name)\n",
        "\n",
        "    try:\n",
        "        # Open and read the file\n",
        "        with open(file_path, 'r', encoding='utf-8') as file:\n",
        "            content = file.read()\n",
        "            # Append the content to the documents list\n",
        "            documents.append(content)\n",
        "        print(f\"Successfully read {file_name}\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: File {file_name} not found.\")\n",
        "    except IOError:\n",
        "        print(f\"Error: Could not read file {file_name}\")\n",
        "\n",
        "# Print the number of documents read\n",
        "print(f\"\\nTotal documents read: {len(documents)}\")\n",
        "\n",
        "# Optionally, print a preview of each document\n",
        "for i, doc in enumerate(documents, 1):\n",
        "    print(f\"\\nDocument {i} preview:\")\n",
        "    print(doc[:50] + \"...\")  # Print first 150 characters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nDFP5OIzhCM",
        "outputId": "d61ff7a2-bac7-4c34-e0b3-3726f3bfb1be"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception ignored on calling ctypes callback function: <function LLModel._prompt_callback at 0x7871f01348b0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gpt4all/_pyllmodel.py\", line 614, in _prompt_callback\n",
            "    @staticmethod\n",
            "KeyboardInterrupt: \n",
            "Exception ignored on calling ctypes callback function: <function LLModel._prompt_callback at 0x7871f01348b0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gpt4all/_pyllmodel.py\", line 614, in _prompt_callback\n",
            "    @staticmethod\n",
            "KeyboardInterrupt: \n",
            "Exception ignored on calling ctypes callback function: <function LLModel._prompt_callback at 0x7871f01348b0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gpt4all/_pyllmodel.py\", line 614, in _prompt_callback\n",
            "    @staticmethod\n",
            "KeyboardInterrupt: \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "In brain tumor radiomics, some key features used include:\n",
            "\n",
            "1. **First-order statistics**: These features describe the distribution of pixel intensities in an image. Examples include:\n",
            "\t* Mean intensity\n",
            "\t* Standard deviation (SD)\n",
            "\t* Skewness\n",
            "\t* Kurtosis\n",
            "2. **Texture features**:\n",
            "\t* First-Order Energy (also known as Angular Second Moment or Uniformity): measures uniformity of pixel intensity distribution, with higher values indicating more homogeneous regions.\n",
            "\t* Brain tumor radiomics involves extracting quantitative features from medical images, such as MRI or CT scans, to analyze and characterize brain tumors. The following are some common key features used in brain tumor radiomics:\n",
            "\n",
            "1. **Original_Firstorder_Energy**: As you mentioned, it's a feature derived from first-order statistics of image intensity values. It represents the magnitude of the energy contained within an image voxel.\n",
            "2. **Gray Level Co-Occurrence Matrix (GLCM) Features**: These features capture In brain tumor radiomics, some key features used in analyzing voxel values within an image region of interest (ROI) include:\n",
            "\n",
            "1. **Energy**: This feature calculates the sum of squared voxel intensities:\n",
            "\t* Formula: `Energy = ∑(Xi + c)^2`, where Xi is the intensity of voxel i, Np is the number of voxels in the ROI, and c is an optional value added to gray levels (voxelArrayShift).\n",
            "\t* Interpretation: Higher The key features used in brain tumor radiomics are:\n",
            "\n",
            "1. **Mean**: The average intensity value across all voxels in a given ROI (Region Of Interest).\n",
            "2. **Median**: The middle value of the intensity values when sorted in ascending order.\n",
            "3. **Standard Deviation** (SD): A measure of the spread or dispersion of the intensity values from their mean value.\n",
            "4. **Variance**: The average of the squared differences between each intensity value and the mean value.\n",
            "5. Brain tumor radiomics involves the extraction of quantitative features from medical images, such as MRI or CT scans, to analyze and predict various aspects of brain tumors. Some key features used in brain tumor radiomics include:\n",
            "\n",
            "1. **First-order statistics**: These features describe the distribution of pixel intensities within a region of interest (ROI). Examples include:\n",
            "\t* Mean intensity\n",
            "\t* Standard deviation (SD) of intensity\n",
            "\t* Energy (a measure of the spread or dispersion of intensity values)\n",
            "2 In brain tumor radiomics, the key features used can include:\n",
            "\n",
            "1. **Intensity histogram**: A statistical summary of pixel intensities in an image.\n",
            "2. **Mean and standard deviation**: Measures of central tendency (mean) and variability (standard deviation).\n",
            "3. **Skewness and kurtosis**: Measures of asymmetry and peakedness of the intensity distribution.\n",
            "4. **Entropy**: A measure of uncertainty or randomness in the intensity values.\n",
            "5. **Energy** (as mentioned): A Brain tumor radiomics involves the extraction of meaningful features from medical images to aid in diagnosis, prognosis, and treatment planning. The key features used in brain tumor radiomics include:\n",
            "\n",
            "1. **Intensity histogram**: A measure of the overall intensity distribution within the region of interest (ROI), which can be useful for characterizing tumors [1].\n",
            "2. **Mean intensity**: The average intensity value within the ROI.\n",
            "3. **Standard deviation** (SD): Measures the spread or dispersion of pixel intensities in Brain tumor radiomics, which involves extracting quantitative features from medical images such as MRI or CT scans, has several key features that are commonly used for brain tumor diagnosis and prognosis. Some of these features include:\n",
            "\n",
            "1. **Texture Features**: These features describe the texture patterns in the image, including:\n",
            "\t* Gray-Level Co-Occurrence Matrix (GLCM) correlation: measures how correlated a given pixel is to its neighboring pixels.\n",
            "\t* GLCM contrast: measures the difference between adjacent gray levels.\n",
            " In brain tumor radiomics, some key features used include:\n",
            "\n",
            "1. **Gray Level Co-occurrence Matrix (GLCM) Correlation**: This feature measures the spatial relationships between pixel intensities in an image, helping to identify patterns and anomalies.\n",
            "2. **Histogram-based Features**:\n",
            "\t* Mean intensity: Average gray level value of the tumor tissue.\n",
            "\t* Standard deviation: Measures the spread or dispersion of gray levels within the tumor region.\n",
            "\t* Skewness: Describes the asym    Brain tumor radiomics, a subfield of medical imaging analytics, employs several key features to analyze brain tumors from MRI scans. Some of these features include:\n",
            "\n",
            "1. **Texture characteristics**: Analysis of texture patterns at different scales and orientations is crucial in identifying specific tissue types or pathological changes.\n",
            "2. **GLCM (Gray-Level Cooccurrence Matrix) Correlation**: This feature measures the correlation between neighboring pixels based on their intensity values, helping to identify areas with consistent textures that might correspond to specific tumor In brain tumor radiomics, the key features used in combination with GLCM (Gray-Level Cooccurrence Matrix) Correlation are:\n",
            "\n",
            "1. **Contrast**: measures the difference between adjacent pixel intensities.\n",
            "2. **Energy**: quantifies the uniformity of gray-level distribution within a region.\n",
            "3. **Homogeneity** (also known as Homogeniety): assesses how similar neighboring pixels' intensity values are.\n",
            "\n",
            "These features, including GLCM Correlation, provide valuable insights into image Brain tumor radiomics is a rapidly evolving field that aims to extract meaningful features from medical images, such as MRI or CT scans, to improve the diagnosis and treatment of brain tumors. The key features used in brain tumor radiomics include:\n",
            "\n",
            "1. **Gray-Level Cooccurrence Matrix (GLCM) features**: These are statistical measures that describe the texture patterns present in an image. GLCM features can be extracted using libraries like OpenCV or ImageJ, as mentioned in your references [3] and\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "# Sample documents from .txt files\n",
        "# Replace these strings with the actual text read from your .txt files\n",
        "# documents = [\n",
        "#     'Text from file 1. Symptoms of brain tumors include headaches, seizures, and vision problems.',\n",
        "#     'Text from file 2. Diagnosis methods involve MRI scan, CT scan, and biopsy.',\n",
        "#     'Text from file 3. Treatment options can include surgery, chemotherapy, and radiation therapy.'\n",
        "# ]\n",
        "\n",
        "def compute_bm25(query, documents, k1=1.5, b=0.75):\n",
        "    # Tokenize documents and query\n",
        "    tokenized_docs = [doc.lower().split() for doc in documents]\n",
        "    tokenized_query = query.lower().split()\n",
        "    doc_freqs = [Counter(doc) for doc in tokenized_docs]\n",
        "    avg_doc_length = np.mean([len(doc) for doc in tokenized_docs])\n",
        "    scores = []\n",
        "\n",
        "    for doc_freq in doc_freqs:\n",
        "        score = 0\n",
        "        doc_length = sum(doc_freq.values())\n",
        "        for term in tokenized_query:\n",
        "            if term in doc_freq:\n",
        "                term_freq = doc_freq[term]\n",
        "                doc_count_containing_term = sum([1 for d in tokenized_docs if term in d])\n",
        "                idf = np.log((len(documents) - doc_count_containing_term + 0.5) / (doc_count_containing_term + 0.5) + 1)\n",
        "                score += idf * (term_freq * (k1 + 1)) / (term_freq + k1 * (1 - b + b * (doc_length / avg_doc_length)))\n",
        "        scores.append(score)\n",
        "\n",
        "    return scores\n",
        "\n",
        "# Initialize the GPT-4 model\n",
        "# model = GPT4All(\"Meta-Llama-3-8B-Instruct.Q4_0.gguf\")\n",
        "\n",
        "def chunk_text(text, max_chunk_size=500):\n",
        "    words = text.split()\n",
        "    chunks = []\n",
        "    current_chunk = []\n",
        "    current_size = 0\n",
        "    for word in words:\n",
        "        if current_size + len(word) + 1 > max_chunk_size:\n",
        "            chunks.append(' '.join(current_chunk))\n",
        "            current_chunk = [word]\n",
        "            current_size = len(word)\n",
        "        else:\n",
        "            current_chunk.append(word)\n",
        "            current_size += len(word) + 1\n",
        "    if current_chunk:\n",
        "        chunks.append(' '.join(current_chunk))\n",
        "    return chunks\n",
        "\n",
        "def generate_diagnosis(query):\n",
        "    # Use BM25 to retrieve relevant documents\n",
        "    scores = compute_bm25(query, documents)\n",
        "    sorted_docs = sorted(enumerate(scores), key=lambda x: x[1], reverse=True)\n",
        "    top_docs = [documents[index] for index, score in sorted_docs if score > 0]\n",
        "    retrieved_data = '\\n'.join(top_docs[:2])  # Get top 2 documents to reduce context size\n",
        "\n",
        "    # Chunk the retrieved data\n",
        "    chunks = chunk_text(retrieved_data)\n",
        "\n",
        "    responses = []\n",
        "    for chunk in chunks:\n",
        "        augmented_query = f\"{query}\\nContext: {chunk}\"\n",
        "\n",
        "        # Generate response using the model\n",
        "        with model.chat_session():\n",
        "            response = model.generate(augmented_query, max_tokens=100)\n",
        "        responses.append(response)\n",
        "\n",
        "    # Combine responses\n",
        "    final_response = ' '.join(responses)\n",
        "    return final_response\n",
        "\n",
        "# Example usage\n",
        "output = generate_diagnosis(\"What are the key features used in brain tumor radiomics?\")\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IE6m8FV2JnK2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAQQutzHJnfr"
      },
      "source": [
        "# Fine-Tune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOzAvv77Jp0b"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer\n",
        "from datasets import Dataset\n",
        "\n",
        "# Load the pre-trained model and tokenizer\n",
        "model_name = \"nomic-ai/gpt4all-j\"  # Replace with your specific GPT4All model\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "\n",
        "# Prepare your custom dataset\n",
        "# This is a simplified example. Replace with your actual data.\n",
        "train_data = [\n",
        "    {\"input\": \"Describe the symptoms of a brain tumor.\", \"output\": \"Common symptoms of brain tumors include headaches, seizures, vision problems, and cognitive changes.\"},\n",
        "    {\"input\": \"What is the significance of GLCM correlation in brain tumor analysis?\", \"output\": \"GLCM correlation in brain tumor analysis helps identify texture patterns in MRI scans, potentially distinguishing between tumor types and healthy tissue.\"},\n",
        "    {\"input\": \"Explain the importance of shape elongation in tumor characterization.\", \"output\": \"Shape elongation in tumor characterization quantifies how stretched a tumor is, which can indicate growth patterns and potential aggressiveness.\"},\n",
        "    # Add more examples...\n",
        "]\n",
        "\n",
        "# Function to tokenize and format the data\n",
        "def tokenize_function(examples):\n",
        "    inputs = [f\"Input: {item['input']}\\nOutput: {item['output']}\" for item in examples]\n",
        "    return tokenizer(inputs, padding=\"max_length\", truncation=True, max_length=512)\n",
        "\n",
        "# Create a Hugging Face Dataset\n",
        "dataset = Dataset.from_list(train_data)\n",
        "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=4,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        ")\n",
        "\n",
        "# Create Trainer instance\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset,\n",
        ")\n",
        "\n",
        "# Fine-tune the model\n",
        "trainer.train()\n",
        "\n",
        "# Save the fine-tuned model\n",
        "model.save_pretrained(\"./fine_tuned_gpt4all\")\n",
        "tokenizer.save_pretrained(\"./fine_tuned_gpt4all\")\n",
        "\n",
        "# Function to generate responses using the fine-tuned model\n",
        "def generate_response(input_text):\n",
        "    input_ids = tokenizer.encode(f\"Input: {input_text}\\nOutput:\", return_tensors=\"pt\")\n",
        "    output = model.generate(input_ids, max_length=150, num_return_sequences=1, no_repeat_ngram_size=2)\n",
        "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "# Example usage\n",
        "print(generate_response(\"What are the key features used in brain tumor radiomics?\"))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "HgEhZuKs3ZOX"
      ],
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyOTEb/bdgs8MWM4jyDbBmbE",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}