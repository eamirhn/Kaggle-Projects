{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eamirhn/Kaggle-Projects/blob/main/ChatBot_Medical.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f27n8ymUHPg3",
        "outputId": "4649244c-d35e-4893-b6d8-14f9bb65de02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip -q install gpt4all"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZDF2DeAHIme",
        "outputId": "d903aaf5-58b9-439c-cb4f-b7998420ef30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: 100%|██████████| 4.66G/4.66G [01:18<00:00, 59.4MiB/s]\n",
            "Verifying: 100%|██████████| 4.66G/4.66G [00:14<00:00, 330MiB/s]\n"
          ]
        }
      ],
      "source": [
        "from gpt4all import GPT4All\n",
        "model = GPT4All(\"Meta-Llama-3-8B-Instruct.Q4_0.gguf\") # downloads / loads a 4.66GB LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwDQmeYqHWAS",
        "outputId": "e4692bd3-130c-420c-f040-b48340f0595f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A fascinating topic!\n",
            "\n",
            "Yes, I'm familiar with brain tumors and radiomic features.\n",
            "\n",
            "Let's break down the three radiomic features you provided:\n",
            "\n",
            "1. **Original_Shape_Elongation**: This feature measures the elongation of a tumor shape in its original form (i.e., before any processing or segmentation). Elongation is defined as the ratio of the longest axis to the shortest axis of an object. In this case, the value 0.7532 indicates that the brain tumor has an elongated shape with a relatively long major axis compared to its minor axes.\n",
            "2. **Original_Firstorder_Energy**: This feature represents the first-order energy moment of the tumor's original intensity histogram. Energy is a measure of the total power or magnitude of the signal, and in this case, it's extremely high (1256789.3245). A higher energy value can indicate that the tumor has a complex texture with many different gray levels.\n",
            "3. **Original_GLCM_Correlation**: This feature measures the correlation between neighboring pixels\n"
          ]
        }
      ],
      "source": [
        "text = \"\"\"\n",
        "Analyze the following radiomic features of a brain tumor and provide a brief explanation:\n",
        "    'original_shape_Elongation': 0.7532,\n",
        "    'original_firstorder_Energy': 1256789.3245,\n",
        "    'original_glcm_Correlation': 0.9876,\n",
        "\"\"\"\n",
        "with model.chat_session():\n",
        "    print(model.generate(f\"Are you Famillier with brian tumors? {text}\", max_tokens=210))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with model.chat_session():\n",
        "    print(model.generate(\"What are the key features used in brain tumor radiomics?\", max_tokens=210))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVxqEq39lvNZ",
        "outputId": "472e5672-b657-41da-d1a2-148b71811551"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Brain tumor radiomics is a rapidly evolving field that aims to extract meaningful information from medical images, such as MRI and CT scans, to improve diagnosis, prognosis, and treatment of brain tumors. The following are some of the key features commonly used in brain tumor radiomics:\n",
            "\n",
            "1. **Texture Features**: These describe the spatial arrangement of pixels or voxels within an image. Examples include:\n",
            "\t* Coarseness: measures the size of texture elements.\n",
            "\t* Contrast: measures the difference between light and dark areas.\n",
            "\t* Homogeneity: measures how uniform the texture is.\n",
            "2. **Shape Features**: These describe the morphology of a tumor, such as its shape, size, and orientation. Examples include:\n",
            "\t* Elliptical fit: measures the degree to which a tumor's shape can be approximated by an ellipse.\n",
            "\t* Sphericity: measures the ratio of a tumor's volume to its surface area.\n",
            "3. **Intensity Features**: These describe the intensity values within an image, such as mean and standard deviation. Examples include:\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A3-5_kNQYbWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RAG"
      ],
      "metadata": {
        "id": "k9orzK_GYciW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install gpt4all langchain faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRdA6GMbYUeO",
        "outputId": "e51a2a84-7ac9-4e47-db13-f7e9ca4c95da"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/27.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.4/27.5 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/27.5 MB\u001b[0m \u001b[31m83.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.6/27.5 MB\u001b[0m \u001b[31m196.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m20.1/27.5 MB\u001b[0m \u001b[31m213.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m27.5/27.5 MB\u001b[0m \u001b[31m219.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m27.5/27.5 MB\u001b[0m \u001b[31m219.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m27.5/27.5 MB\u001b[0m \u001b[31m219.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.5/27.5 MB\u001b[0m \u001b[31m75.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install -U langchain-community\n"
      ],
      "metadata": {
        "id": "bW3Q-e3LYycO"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gpt4all langchain faiss-cpu\n",
        "from gpt4all import GPT4All\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.llms import GPT4All as LangChainGPT4All\n",
        "from langchain.document_loaders import TextLoader\n",
        "\n",
        "# Load and process documents\n",
        "docs = []\n",
        "for file in [\"/content/drive/MyDrive/RAG/doc1_original_shape_Elongation.txt\",\n",
        "              \"/content/drive/MyDrive/RAG/doc2_original_firstorder_Energy.txt\",\n",
        "              \"/content/drive/MyDrive/RAG/doc3_original_glcm_Correlation.txt\"]:\n",
        "    loader = TextLoader(file)\n",
        "    docs.extend(loader.load())\n",
        "\n",
        "# Split documents into chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "splits = text_splitter.split_documents(docs)\n",
        "\n",
        "# Create embeddings and vector store\n",
        "embeddings = HuggingFaceEmbeddings()\n",
        "vectorstore = FAISS.from_documents(splits, embeddings)\n",
        "\n",
        "# Initialize GPT4All model\n",
        "model = LangChainGPT4All(model=\"Meta-Llama-3-8B-Instruct.Q4_0.gguf\")\n",
        "\n",
        "# Create RetrievalQA chain\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=model,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=vectorstore.as_retriever()\n",
        ")\n",
        "\n",
        "# Function to generate response\n",
        "def generate_response(query):\n",
        "    return qa_chain.run(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmUgjEPKYVh7",
        "outputId": "f744a61c-2ecd-402a-efc1-17a3618b546f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-e20624ddb927>:23: LangChainDeprecationWarning: Default values for HuggingFaceEmbeddings.model_name were deprecated in LangChain 0.2.16 and will be removed in 0.4.0. Explicitly pass a model_name to the HuggingFaceEmbeddings constructor instead.\n",
            "  embeddings = HuggingFaceEmbeddings()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"\n",
        "Analyze the following radiomic features of a brain tumor and provide a brief explanation:\n",
        "    'original_shape_Elongation': 0.7532,\n",
        "    'original_firstorder_Energy': 1256789.3245,\n",
        "    'original_glcm_Correlation': 0.9876,\n",
        "\"\"\"\n",
        "query = f\"Are you familiar with brain tumors? {text}\"\n",
        "response = generate_response(query)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3oKfmz4dzNA",
        "outputId": "db8b9046-46d3-49c7-d3a2-c85a65f93b16"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-e20624ddb927>:38: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  return qa_chain.run(query)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n",
            "I am familiar with brain tumors.\n",
            "\n",
            "The provided radiomic features are:\n",
            "\n",
            "1. 'original_shape_Elongation': This feature measures the elongation of a tumor, which is defined as the ratio between the major axis length and the minor axis length of the bounding box. A value closer to 1 indicates a more elongated shape, while a value closer to 0 suggests a shape closer to a sphere.\n",
            "\n",
            "Value: 0.7532\n",
            "\n",
            "This relatively high value (closer to 1) may indicate that the tumor has an irregular or elongated shape, which could be associated with certain types of brain tumors.\n",
            "\n",
            "2. 'original_firstorder_Energy': This feature quantifies the sum of squared voxel intensities within a defined region of interest (ROI), such as a brain tumor. Higher energy values can reflect regions with dense cellularity or increased contrast enhancement, often seen in high-grade tumors.\n",
            "\n",
            "Value: 1256789.3245\n",
            "\n",
            "This extremely high value may suggest that the tumor has an intense signal intensity and heterogeneity, which could be indicative of aggressive features.\n",
            "\n",
            "3. 'original_glcm_Correlation': This feature measures the linear dependency of gray-level values in an image, providing insights into the spatial relationships and patterns of pixel intensities within\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "import pickle\n",
        "\n",
        "# Assuming 'vectorstore' is your FAISS object\n",
        "faiss.write_index(vectorstore.index, \"vector_store.index\")\n",
        "\n",
        "# Save any additional metadata if necessary\n",
        "with open(\"vector_store_metadata.pkl\", \"wb\") as f:\n",
        "    pickle.dump(vectorstore.metadata, f)\n"
      ],
      "metadata": {
        "id": "T39JyLHA1ZoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "import pickle\n",
        "\n",
        "# Load the FAISS index\n",
        "index = faiss.read_index(\"vector_store.index\")\n",
        "\n",
        "# Load any additional metadata if necessary\n",
        "with open(\"vector_store_metadata.pkl\", \"rb\") as f:\n",
        "    metadata = pickle.load(f)\n",
        "\n",
        "# Create a new vector store using the loaded index\n",
        "vectorstore = FAISS(index=index, metadata=metadata)\n"
      ],
      "metadata": {
        "id": "5vHSBXj91Z_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# Assuming you've already set up the RAG system as in the previous code\n",
        "\n",
        "# Function to generate response with timing\n",
        "def generate_timed_response(query):\n",
        "    start_time = time.time()\n",
        "    response = qa_chain.run(query)\n",
        "    end_time = time.time()\n",
        "    processing_time = end_time - start_time\n",
        "    return response, processing_time\n",
        "\n",
        "# Example usage\n",
        "query = \"\"\"Analyze the following radiomic features of a brain tumor and provide a brief explanation:\n",
        "    'original_shape_Elongation': 0.7532,\n",
        "    'original_firstorder_Energy': 1256789.3245,\n",
        "    'original_glcm_Correlation': 0.9876\"\"\"\n",
        "\n",
        "response, processing_time = generate_timed_response(query)\n",
        "\n",
        "print(f\"Query: {query}\\n\")\n",
        "print(f\"Response: {response}\\n\")\n",
        "print(f\"Processing time: {processing_time:.2f} seconds\")\n",
        "\n",
        "# You can now easily query the system multiple times\n",
        "queries = [\n",
        "    \"What are the common symptoms of brain tumors?\",\n",
        "    \"How does tumor shape affect prognosis?\",\n",
        "    \"Explain the significance of GLCM correlation in tumor analysis.\"\n",
        "]\n",
        "\n",
        "for query in queries:\n",
        "    response, processing_time = generate_timed_response(query)\n",
        "    print(f\"\\nQuery: {query}\")\n",
        "    print(f\"Response: {response}\")\n",
        "    print(f\"Processing time: {processing_time:.2f} seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0AKML5LjgneY",
        "outputId": "fb6cfb5e-9b51-41c1-e1e5-6f47f9d92e7d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception ignored on calling ctypes callback function: <function LLModel._prompt_callback at 0x7a60f781a5f0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gpt4all/_pyllmodel.py\", line 614, in _prompt_callback\n",
            "    @staticmethod\n",
            "KeyboardInterrupt: \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query: Analyze the following radiomic features of a brain tumor and provide a brief explanation:\n",
            "    'original_shape_Elongation': 0.7532,\n",
            "    'original_firstorder_Energy': 1256789.3245,\n",
            "    'original_glcm_Correlation': 0.9876\n",
            "\n",
            "Response: \n",
            "\n",
            "Processing time: 296.66 seconds\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception ignored on calling ctypes callback function: <function LLModel._prompt_callback at 0x7a60f781a5f0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gpt4all/_pyllmodel.py\", line 614, in _prompt_callback\n",
            "    @staticmethod\n",
            "KeyboardInterrupt: \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Query: What are the common symptoms of brain tumors?\n",
            "Response: \n",
            "Processing time: 12.75 seconds\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception ignored on calling ctypes callback function: <function LLModel._prompt_callback at 0x7a60f781a5f0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gpt4all/_pyllmodel.py\", line 614, in _prompt_callback\n",
            "    @staticmethod\n",
            "KeyboardInterrupt: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Query: How does tumor shape affect prognosis?\n",
            "Response: \n",
            "Processing time: 146.75 seconds\n",
            "\n",
            "Query: Explain the significance of GLCM correlation in tumor analysis.\n",
            "Response:  The original_ glcm_Correlation feature measures the linear dependency of gray-level values within a tumor ROI, offering insights into tissue homogeneity and potential tumor characterization. It can provide valuable information about the spatial relationships and patterns of pixel intensities within a region of interest (ROI), such as a brain tumor. Higher correlation values may indicate more homogeneous tissue structures, while lower values suggest heterogeneity, which can be associated with tumor aggressiveness. Variations in texture features like GLCM Correlation can assist in differentiating tumor types and grades, potentially aiding in diagnosis and treatment planning. Its interpretation requires careful consideration of imaging protocols, accurate tumor segmentation, and integration with other clinical data.\n",
            "Processing time: 2126.94 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgEhZuKs3ZOX"
      },
      "source": [
        "# Simple Method RAG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "N15v1emazdDW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b24ac82-cb1a-44a5-c0fd-c6476f732361"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: File not found - file1.txt\n",
            "Error: File not found - file2.txt\n",
            "Error: File not found - file3.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored on calling ctypes callback function: <function LLModel._prompt_callback at 0x7a60f781a5f0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gpt4all/_pyllmodel.py\", line 614, in _prompt_callback\n",
            "    @staticmethod\n",
            "KeyboardInterrupt: \n",
            "Exception ignored on calling ctypes callback function: <function LLModel._callback_decoder.<locals>._raw_callback at 0x7a60f7a888b0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gpt4all/_pyllmodel.py\", line 573, in _raw_callback\n",
            "    def _raw_callback(token_id: int, response: bytes) -> bool:\n",
            "KeyboardInterrupt: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Brain tumors can cause a wide range of symptoms, depending on their location, size, and type\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from gpt4all import GPT4All\n",
        "\n",
        "# Define the RetrievalSystem class\n",
        "class RetrievalSystem:\n",
        "    def __init__(self, file_paths):\n",
        "        self.data = self.load_files(file_paths)\n",
        "\n",
        "    def load_files(self, file_paths):\n",
        "        data = []\n",
        "        for file_path in file_paths:\n",
        "            try:\n",
        "                with open(file_path, 'r') as file:\n",
        "                    data.append(file.read())\n",
        "            except FileNotFoundError:\n",
        "                print(f\"Error: File not found - {file_path}\")\n",
        "        return data\n",
        "\n",
        "    def retrieve(self, query):\n",
        "        # Simple retrieval: return all content for demo purposes\n",
        "        # In a real-world scenario, you would implement a more sophisticated retrieval method\n",
        "        return ' '.join(self.data)\n",
        "\n",
        "# Initialize the retrieval system with the paths to the .txt files\n",
        "file_paths = ['file1.txt', 'file2.txt', 'file3.txt']\n",
        "retrieval_system = RetrievalSystem(file_paths)\n",
        "\n",
        "# Initialize the GPT-4 model\n",
        "model = GPT4All(\"Meta-Llama-3-8B-Instruct.Q4_0.gguf\")\n",
        "\n",
        "# Function to generate diagnosis using RAG\n",
        "def generate_diagnosis(query):\n",
        "    # Retrieve relevant information\n",
        "    retrieved_data = retrieval_system.retrieve(query)\n",
        "\n",
        "    # Combine retrieved data with the query for context\n",
        "    augmented_query = f\"{query}\\n{retrieved_data}\"\n",
        "\n",
        "    # Generate response using the model\n",
        "    with model.chat_session():\n",
        "        response = model.generate(augmented_query, max_tokens=210)\n",
        "\n",
        "    return response\n",
        "\n",
        "# Example usage\n",
        "output = generate_diagnosis(\"What are the symptoms of brain tumors?\")\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAQQutzHJnfr"
      },
      "source": [
        "# Fine-Tune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOzAvv77Jp0b"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer\n",
        "from datasets import Dataset\n",
        "\n",
        "# Load the pre-trained model and tokenizer\n",
        "model_name = \"nomic-ai/gpt4all-j\"  # Replace with your specific GPT4All model\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "\n",
        "# Prepare your custom dataset\n",
        "# This is a simplified example. Replace with your actual data.\n",
        "train_data = [\n",
        "    {\"input\": \"Describe the symptoms of a brain tumor.\", \"output\": \"Common symptoms of brain tumors include headaches, seizures, vision problems, and cognitive changes.\"},\n",
        "    {\"input\": \"What is the significance of GLCM correlation in brain tumor analysis?\", \"output\": \"GLCM correlation in brain tumor analysis helps identify texture patterns in MRI scans, potentially distinguishing between tumor types and healthy tissue.\"},\n",
        "    {\"input\": \"Explain the importance of shape elongation in tumor characterization.\", \"output\": \"Shape elongation in tumor characterization quantifies how stretched a tumor is, which can indicate growth patterns and potential aggressiveness.\"},\n",
        "    # Add more examples...\n",
        "]\n",
        "\n",
        "# Function to tokenize and format the data\n",
        "def tokenize_function(examples):\n",
        "    inputs = [f\"Input: {item['input']}\\nOutput: {item['output']}\" for item in examples]\n",
        "    return tokenizer(inputs, padding=\"max_length\", truncation=True, max_length=512)\n",
        "\n",
        "# Create a Hugging Face Dataset\n",
        "dataset = Dataset.from_list(train_data)\n",
        "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=4,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        ")\n",
        "\n",
        "# Create Trainer instance\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset,\n",
        ")\n",
        "\n",
        "# Fine-tune the model\n",
        "trainer.train()\n",
        "\n",
        "# Save the fine-tuned model\n",
        "model.save_pretrained(\"./fine_tuned_gpt4all\")\n",
        "tokenizer.save_pretrained(\"./fine_tuned_gpt4all\")\n",
        "\n",
        "# Function to generate responses using the fine-tuned model\n",
        "def generate_response(input_text):\n",
        "    input_ids = tokenizer.encode(f\"Input: {input_text}\\nOutput:\", return_tensors=\"pt\")\n",
        "    output = model.generate(input_ids, max_length=150, num_return_sequences=1, no_repeat_ngram_size=2)\n",
        "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "# Example usage\n",
        "print(generate_response(\"What are the key features used in brain tumor radiomics?\"))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "HgEhZuKs3ZOX"
      ],
      "gpuType": "T4",
      "provenance": [],
      "mount_file_id": "1tvH2wZzFsfj42UiTzTkSJ5u9FP32F_6C",
      "authorship_tag": "ABX9TyOwAon9NvfKsJlrLCQaktmc",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}